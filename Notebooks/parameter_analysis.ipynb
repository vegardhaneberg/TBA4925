{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.client import open_url\n",
    "from datetime import datetime\n",
    "from calendar import monthrange, month_name\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import cdsapi\n",
    "import math\n",
    "\n",
    "# Functions (defs) from other notebooks\n",
    "import ipynb.fs.defs.CreateCollocatedDataFrame as ccdf\n",
    "\n",
    "# Interpolation\n",
    "from scipy.interpolate import RegularGridInterpolator, LinearNDInterpolator\n",
    "import scipy.interpolate.interpnd\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt, figure\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.colors import LogNorm\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from plotly import express as px\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data frame options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set boolean parameters\n",
    "plot_distributions_boolean = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Interpolated DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_df = pd.read_csv('/Users/madsrindal/Desktop/Intervals/24-80-19-85/InterpolatedDF-withCYGNSSQFs-[24-80-19-85].csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions used for data processing before the utilization of ML \n",
    "\n",
    "# FILTER SMAP NAN VALUES\n",
    "print('Filtering SMAP NaN values...')\n",
    "print('-'*60)\n",
    "before = india_df.shape[0]\n",
    "india_df = ccdf.filter_nan_smap_sm(india_df)\n",
    "india_df = ccdf.filter_nan_smap_vo(india_df)\n",
    "india_df = ccdf.filter_nan_smap_sr(india_df)\n",
    "after = india_df.shape[0]\n",
    "print('Removed ' + str(before-after) + ' rows of SMAP NaN values')\n",
    "print('-'*60)\n",
    "\n",
    "## FILTER QUALITY FLAGS\n",
    "print('\\nFiltering quality flags...')\n",
    "print('-'*40)\n",
    "before = india_df.shape[0]\n",
    "india_df = ccdf.filter_quality_flags_1(india_df)\n",
    "after = india_df.shape[0]\n",
    "print('Removed ' + str(before-after) + ' rows due to CYGNSS QFs')\n",
    "print('-'*40)\n",
    "\n",
    "## COMPUTE BLOCK_CODE\n",
    "print('\\nComputing block codes...')\n",
    "india_df = ccdf.compute_block_code(india_df)\n",
    "\n",
    "## SCALE SURFACE REFLECTIVITY VALUES (REMOVE THE MIN VALUE FROM ALL OTHER VALUES)\n",
    "print('\\nScaling surface reflectivity values...')\n",
    "india_df = ccdf.scale_sr_values(india_df)\n",
    "\n",
    "## COMPUTE DAILY HOUR (0-23)\n",
    "print('\\nComputing daily hour from 0-23...')\n",
    "india_df = ccdf.compute_daily_hour_column(india_df)\n",
    "\n",
    "## COMPUTE TIME OF DAY (morning/day/afternoon/night)\n",
    "print('\\nComputing time of day (morning/day/afternoon/night)...')\n",
    "india_df = ccdf.compute_time_of_day(india_df)\n",
    "\n",
    "print('##### PREPROCESSING DONE #####')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('India Data Frame Shape: ', india_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [india_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incidence Angle Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_distributions_boolean:\n",
    "\n",
    "    for df in df_list:\n",
    "\n",
    "        print('Min: ', df['sp_inc_angle'].min())\n",
    "        print('Max: ', df['sp_inc_angle'].max())\n",
    "\n",
    "        plt.hist(df['sp_inc_angle'])\n",
    "        plt.title('Incidence Angle Measurements 2020', fontsize=18)\n",
    "        plt.ylabel('Count', fontsize=12)\n",
    "        plt.xlabel('Incidence angle', fontsize=12)\n",
    "        # plt.savefig('/Users/madsrindal/Desktop/Plots/IncidenceAngleDistribution2020.png', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_distributions_boolean:\n",
    "    \n",
    "    incidence_angle_intervals = [5, 10, 20]\n",
    "\n",
    "    for df in df_list:\n",
    "\n",
    "        max_values = []\n",
    "        for angle in incidence_angle_intervals:\n",
    "\n",
    "            corr_list = []\n",
    "            inc_angle = []\n",
    "\n",
    "            for i in range(0, 72, 2):\n",
    "                chosen_df = df[df['sp_inc_angle'] >= i]\n",
    "                chosen_df = chosen_df[chosen_df['sp_inc_angle'] <= i+angle]\n",
    "                corr = chosen_df['smap_sm'].corr(chosen_df['sr'])\n",
    "                corr_list.append(corr)\n",
    "                inc_angle.append(i)\n",
    "\n",
    "            max_values.append(max(corr_list))\n",
    "            plt.plot(inc_angle, corr_list, linewidth=4.0, label='IA Interval: ' + str(angle))\n",
    "            plt.title('SMAP SM and SR Correlation', fontsize=18)\n",
    "            plt.ylabel('Correlation', fontsize=12)\n",
    "            plt.xlabel('Incidence angle', fontsize=12)\n",
    "            # plt.savefig('/Users/madsrindal/Desktop/Plots/IncidenceAngleCorrelation2020smap.png')\n",
    "\n",
    "        plt.legend(fontsize='small')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vegetation Opacity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_distributions_boolean:\n",
    "\n",
    "    for df in df_list:\n",
    "        print('Min: ', df['smap_vo'].min())\n",
    "        print('Max: ', df['smap_vo'].max())\n",
    "\n",
    "        plt.hist(df['smap_vo'])\n",
    "        plt.title('SMAP Vegetation Opacity Measurements', fontsize=18)\n",
    "        plt.ylabel('Count', fontsize=12)\n",
    "        plt.xlabel('Vegetation opacity', fontsize=12)\n",
    "        # plt.savefig('/Users/madsrindal/Desktop/Plots/IncidenceAngleDistribution2020.png', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Rougness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_distributions_boolean:\n",
    "\n",
    "    for df in df_list:\n",
    "        print('Min: ', df['smap_surface_roughness'].min())\n",
    "        print('Max: ', df['smap_surface_roughness'].max())\n",
    "\n",
    "        plt.hist(df['smap_surface_roughness'])\n",
    "        plt.title('SMAP Surface Roughness Factor', fontsize=18)\n",
    "        plt.ylabel('Count', fontsize=12)\n",
    "        plt.xlabel('Surface Roughness Factor', fontsize=12)\n",
    "        # plt.savefig('/Users/madsrindal/Desktop/Plots/IncidenceAngleDistribution2020.png', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smap_df = pd.read_csv('/Users/madsrindal/Desktop/Intervals/24-80-19-85/SMAP-allYears-withQFs-[24-80-19-85].csv')\n",
    "filtered_smap_df = ccdf.filter_smap_qfs(smap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min/Max values for original data frame:')\n",
    "print('Min: ', smap_df['surface_roughness'].min())\n",
    "print('Max: ', smap_df['surface_roughness'].max())\n",
    "\n",
    "print('\\nMin/Max values for filtered data frame:')\n",
    "print('Min: ', filtered_smap_df['surface_roughness'].min())\n",
    "print('Max: ', filtered_smap_df['surface_roughness'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    corr = df['smap_sm'].corr(df['sr'])\n",
    "    print('SM / SR - Correlation: ', corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "\n",
    "import catboost as cb\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = india_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df['rx_to_sp_range'] = ml_df['rx_to_sp_range'].apply(lambda x: float(x))\n",
    "ml_df['tx_to_sp_range'] = ml_df['tx_to_sp_range'].apply(lambda x: float(x))\n",
    "ml_df['hours_after_jan_2019'] = ml_df['hours_after_jan_2019'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns\n",
    "cols_to_drop = ['unique_track_id', 'qf_ok']\n",
    "ml_df.drop(cols_to_drop, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'smap_sm'\n",
    "X = ml_df.loc[:, ml_df.columns != target_variable]\n",
    "y = ml_df.loc[:, ml_df.columns == target_variable]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_indices = np.where(X_train.dtypes != float)[0]\n",
    "print('Categorical features on indices: ', cat_features_indices)\n",
    "train_dataset = cb.Pool(X_train, y_train, cat_features=cat_features_indices) \n",
    "test_dataset = cb.Pool(X_test, y_test, cat_features=cat_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Columns: ', list(X_train.columns))\n",
    "print('--------------'*8)\n",
    "print('Cat Columns: ', list(X_train.iloc[:, cat_features_indices].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cb.CatBoostRegressor(loss_function='RMSE')\n",
    "\n",
    "# if load_pretrained_model:\n",
    "#     model.load_model('catboost_model_08052022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 31 runs per iteration interval -> 94 in total\n",
    "# Finished in 6.3 hours\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid = {'iterations': [100, 150, 200],\n",
    "        'learning_rate': [0.03, 0.1],\n",
    "        'depth': [2, 4, 6, 8],\n",
    "        'l2_leaf_reg': [0.2, 0.5, 1, 3]}\n",
    "model.grid_search(grid, train_dataset)\n",
    "\n",
    "print('\\n\\n' + '#'*50)\n",
    "print('Finished grid search in ' + str(time.time()-start_time) + ' seconds')\n",
    "print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model_when_done:\n",
    "    model_name = 'model_name'\n",
    "    model.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "print('Testing performance')\n",
    "# print('Incidence angle interval: ', inc_angles)\n",
    "print('RMSE: ', rmse)\n",
    "print('R2: ', r2)\n",
    "#print('RMSE: {:.2f}'.format(rmse))\n",
    "#print('R2: {:.2f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance = model.feature_importances_.argsort()\n",
    "plt.barh(X_train.columns[sorted_feature_importance], \n",
    "        model.feature_importances_[sorted_feature_importance], \n",
    "        color='blue')\n",
    "plt.title(\"CatBoost Feature Importance\", fontsize=18)\n",
    "plt.xlabel(\"Importance Percentage\", fontsize=12)\n",
    "# plt.savefig('/Users/madsrindal/Desktop/Plots/CatBoostFeatureimportance', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save / Load model with pickle\n",
    "# pickle.dump(model, open(model_name + '.pkl', 'wb')) # Save\n",
    "# pickled_model = pickle.load(open(model_name + '.pkl', 'rb')) # Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE FOR MAKING A SMALLER AREA USED TO TEST AUTO_ML FUNCTIONALITY AND BEST MODELS ##\n",
    "\n",
    "def filter_location(df, location):\n",
    "    filtered_df = df[df.sp_lat < location[0]]\n",
    "    filtered_df = filtered_df[filtered_df.sp_lat > location[2]]\n",
    "    filtered_df = filtered_df[filtered_df.sp_lon < location[3]]\n",
    "    filtered_df = filtered_df[filtered_df.sp_lon > location[1]]\n",
    "    return filtered_df\n",
    "\n",
    "print('Original ml_df shape: ', ml_df.shape)\n",
    "\n",
    "india_small_area = [22.5, 81, 20.5, 83]\n",
    "\n",
    "ml_df_small = filter_location(ml_df, india_small_area)\n",
    "\n",
    "print('Smaller area ml_df shape: ', ml_df_small.shape)\n",
    "print('New ml_df shape: ', ml_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'smap_sm'\n",
    "X_auto = ml_df_small.loc[:, ml_df_small.columns != target_variable]\n",
    "y_auto = ml_df_small.loc[:, ml_df_small.columns == target_variable]\n",
    "\n",
    "X_train_auto, X_test_auto, y_train_auto, y_test_auto = train_test_split(X_auto, y_auto, test_size = 0.2, random_state=5)\n",
    "\n",
    "train_auto = pd.concat([X_train_auto, y_train_auto], axis=1, join='inner')\n",
    "test_auto = pd.concat([X_test_auto, y_test_auto], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h2o = h2o.H2OFrame(train_auto)\n",
    "test_h2o = h2o.H2OFrame(test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h2o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_h2o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'smap_sm'\n",
    "x = train_h2o.columns\n",
    "x.remove(y)\n",
    "\n",
    "train_h2o['ddm_channel'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['spacecraft_num'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['day_of_year'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['track_id'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['prn_code'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['quality_flags'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['quality_flags_2'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['year'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['hours_after_jan_2019'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['block_code'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['daily_hour'] = train_h2o['time_of_day'].asfactor()\n",
    "train_h2o['time_of_day'] = train_h2o['time_of_day'].asfactor()\n",
    "\n",
    "test_h2o['ddm_channel'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['spacecraft_num'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['day_of_year'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['track_id'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['prn_code'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['quality_flags'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['quality_flags_2'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['year'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['hours_after_jan_2019'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['block_code'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['daily_hour'] = test_h2o['time_of_day'].asfactor()\n",
    "test_h2o['time_of_day'] = test_h2o['time_of_day'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(balance_classes=False, max_models = 10, seed = 1)\n",
    "aml.train(x = x, y = y, training_frame = train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = aml.get_best_model(algorithm=\"xgboost\", criterion=\"rmse\")\n",
    "model2 = aml.get_best_model(algorithm=\"GBM\", criterion=\"rmse\")\n",
    "model3 = aml.get_best_model(algorithm=\"DRF\", criterion=\"rmse\")\n",
    "model4 = aml.get_best_model(criterion='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = model1.predict(test_h2o)\n",
    "preds2 = model2.predict(test_h2o)\n",
    "preds3 = model3.predict(test_h2o)\n",
    "preds4 = model4.predict(test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_xgboost = mean_squared_error(h2o.as_list(test_h2o['smap_sm'])['smap_sm'], predictions1['predict'], squared=False)\n",
    "rmse_gbm = mean_squared_error(h2o.as_list(test_h2o['smap_sm'])['smap_sm'], predictions2['predict'], squared=False)\n",
    "rmse_drf = mean_squared_error(h2o.as_list(test_h2o['smap_sm'])['smap_sm'], predictions3['predict'], squared=False)\n",
    "rmse_best = mean_squared_error(h2o.as_list(test_h2o['smap_sm'])['smap_sm'], predictions4['predict'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE XGBOOST: ', rmse_xgboost)\n",
    "print('RMSE GBM: ', rmse_gbm)\n",
    "print('RMSE DRF: ', rmse_drf)\n",
    "print('RMSE BEST: ', rmse_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
