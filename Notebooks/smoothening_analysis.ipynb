{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "from progressbar import progressbar\n",
    "from astropy.convolution import convolve\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from regions import RectanglePixelRegion, PixCoord\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "from random import random\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "from progressbar import progressbar\n",
    "from astropy.convolution import convolve\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import xarray as xr\n",
    "import random\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from itertools import product\n",
    "from scipy.signal import savgol_filter\n",
    "tqdm.pandas()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "flooded_area = {'north': 28.1, 'south': 26.6, 'west': 58.9, 'east': 60.7}\n",
    "iran = {'north': 31, 'south': 26, 'west': 59, 'east': 64}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions CYGNSS\n",
    "\n",
    "def filter_cygnss_df(df: pd.DataFrame, area: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters cygnss dataframe\n",
    "    :param df: pd.Dataframe\n",
    "    :param area: [N, W, S, E]\n",
    "    :return: pd.Dataframe\n",
    "    \"\"\"\n",
    "    if 'sp_lat' in df.columns:\n",
    "        new_df = df[df['sp_lat'] <= area['north']]\n",
    "        new_df = new_df[new_df['sp_lat'] >= area['south']]\n",
    "        new_df = new_df[new_df['sp_lon'] >= area['west']]\n",
    "        new_df = new_df[new_df['sp_lon'] <= area['east']]\n",
    "    else:\n",
    "        new_df = df[df['lat'] <= area['north']]\n",
    "        new_df = new_df[new_df['lat'] >= area['south']]\n",
    "        new_df = new_df[new_df['long'] >= area['west']]\n",
    "        new_df = new_df[new_df['long'] <= area['east']]\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def calculate_sr_value(snr, p_r, g_t, g_r, d_ts, d_sr):\n",
    "    return snr - p_r - g_t - g_r - (20 * np.log10(0.19)) + (20 * np.log10(d_ts + d_sr)) + (20 * np.log10(4 * np.pi))\n",
    "\n",
    "\n",
    "def compute_surface_reflectivity(df):\n",
    "    df['sr'] = df.apply(\n",
    "        lambda row: calculate_sr_value(row.ddm_snr, row.gps_tx_power_db_w, row.gps_ant_gain_db_i, row.sp_rx_gain,\n",
    "                                       row.tx_to_sp_range, row.rx_to_sp_range), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_hours_after_jan(df):\n",
    "    df['hours_after_jan_2020'] = df.apply(\n",
    "        lambda row: calculate_hours_after_jan_value(row.day_of_year, row.ddm_timestamp_utc), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_hours_after_jan_value(day_of_year, ddm_timestamp):\n",
    "    return (day_of_year - 1) * 24 + ddm_timestamp / (60 * 60)\n",
    "\n",
    "\n",
    "def filter_inc_angle(df: pd.DataFrame, angles: list):\n",
    "    df = df[df['sp_inc_angle'] >= angles[0]]\n",
    "    df = df[df['sp_inc_angle'] <= angles[1]]\n",
    "    return df\n",
    "\n",
    "def get_cygnss_df(root_path: str, days: list, month: int, area: dict, inc_angle_interval: list) -> pd.DataFrame:\n",
    "    if month < 10:\n",
    "        file_start = '/raw_main_df_2020_0' + str(month) + '_'\n",
    "    else:\n",
    "        file_start = '/raw_main_df_2020_' + str(month) + '_'\n",
    "            \n",
    "    file_ending = 'of31.csv'\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for day in tqdm(days):\n",
    "        current_path = root_path + file_start + str(day) + file_ending\n",
    "        current_cygnss_df = compute_surface_reflectivity(filter_cygnss_df(pd.read_csv(current_path), area))\n",
    "        current_cygnss_df = filter_inc_angle(current_cygnss_df, inc_angle_interval)\n",
    "        current_cygnss_df = compute_hours_after_jan(current_cygnss_df)\n",
    "        df = df.append(current_cygnss_df)\n",
    "    \n",
    "    \n",
    "    return df.rename(columns={'sp_lat': 'lat', 'sp_lon': 'long'})\n",
    "\n",
    "\n",
    "def filter_quality_flags_1(filter_df, use_print=True):\n",
    "    if use_print:\n",
    "        print('Removing bad quality CYGNSS measurements...')\n",
    "    rows_before_removal = filter_df.shape[0]\n",
    "    filter_df['qf_ok'] = filter_df.apply(\n",
    "        lambda row: (2 or 4 or 5 or 8 or 16 or 17) not in generate_qf_list(int(row.quality_flags)), axis=1)\n",
    "    filter_df = filter_df[filter_df['qf_ok']]\n",
    "    rows_after_removal = filter_df.shape[0]\n",
    "    \n",
    "    if use_print:\n",
    "        print('Removed ' + str(rows_before_removal - rows_after_removal) + ' rows of bad overall quality')\n",
    "    \n",
    "    return filter_df\n",
    "\n",
    "\n",
    "def generate_qf_list(qf_number):\n",
    "    qf_list = []\n",
    "    binary = format(qf_number, 'b')\n",
    "    for i in range(len(binary)):\n",
    "        if binary[i] == '1':\n",
    "            qf_list.append(2 ** (int(i)))\n",
    "\n",
    "    return qf_list\n",
    "\n",
    "\n",
    "def smoothening(df: pd.DataFrame, area: dict, sigma: float, target_value='swvl1') -> pd.DataFrame:\n",
    "    df = df.sort_values(['lat', 'long'], ascending=(False, True))\n",
    "    lats = np.arange(area['north'], area['south'] - 0.05, -0.1)\n",
    "    lats = np.around(lats, 1)\n",
    "    longs = np.arange(area['west'], area['east'] + 0.05, 0.1)\n",
    "    longs = np.around(longs, 1)\n",
    "\n",
    "    target_values = np.array(df[target_value]).reshape(len(lats), len(longs))\n",
    "    target_values = gaussian_filter(target_values, sigma=sigma)\n",
    "    target_values = target_values.flatten()\n",
    "    df[target_value] = target_values\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def grid_box(df, target_value='sr', use_median=True):\n",
    "    df['lat'] = df['lat'].apply(lambda x: round(x, 1))\n",
    "    df['long'] = df['long'].apply(lambda x: round(x, 1))\n",
    "    \n",
    "    if use_median:\n",
    "        df = df.groupby(['long', 'lat'], as_index=False)[target_value].median()\n",
    "    else:\n",
    "        df = df.groupby(['long', 'lat'], as_index=False)[target_value].mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def interpolate(df: pd.DataFrame, target_value, lat_name='lat', long_name='long') -> LinearNDInterpolator:\n",
    "    coordinates = list(zip(list(df[lat_name]), list(df[long_name])))\n",
    "    target = df[target_value]\n",
    "    interpolation_function = LinearNDInterpolator(coordinates, target)\n",
    "    return interpolation_function\n",
    "\n",
    "\n",
    "def smoothening_analysis(cyg_df, truth_df, area, start_sig=0, end_sig=10, interval=0.1, use_plot=True):\n",
    "    \n",
    "    if use_plot:\n",
    "        universal_plot(cyg_df, 'sr', title='CYGNSS SR', bar_title='SR [dB]', save=None, dot_size=14)\n",
    "    \n",
    "    merged_without_smoothening = pd.merge(cyg_df, truth_df, on=['lat', 'long'], how='inner')\n",
    "    no_smoothening_correlation = merged_without_smoothening['sr'].corr(merged_without_smoothening['smap_sm'])\n",
    "    \n",
    "    correlations_smooth = {}\n",
    "    for sigma in np.arange(start_sig, end_sig, interval):\n",
    "        smooth_df = smoothening(cyg_df, area, sigma, 'sr')\n",
    "        merged_df_smooth_analysis = pd.merge(smooth_df, truth_df, on=['lat', 'long'], how='inner')\n",
    "        correlations_smooth[sigma] = merged_df_smooth_analysis['smap_sm'].corr(merged_df_smooth_analysis['sr'])\n",
    "    \n",
    "    if use_plot:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes()\n",
    "        ax.plot(correlations_smooth.keys(), correlations_smooth.values())\n",
    "    \n",
    "    max_index = list(correlations_smooth.values()).index(max(list(correlations_smooth.values())))\n",
    "    \n",
    "    print('Correlation without smoothening:', round(no_smoothening_correlation, 3))\n",
    "    print('Max correlation:', round(max(list(correlations_smooth.values())), 3), 'using sigma:', \n",
    "          round(list(correlations_smooth.keys())[max_index], 2))\n",
    "    \n",
    "    return correlations_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions SMAP\n",
    "\n",
    "def get_smap(path: str, printing=False):\n",
    "    ds = nc.Dataset(path)\n",
    "    sm = ds['Soil_Moisture_Retrieval_Data_AM']\n",
    "\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    moistures = []\n",
    "    times = []\n",
    "    qfs = []\n",
    "    landcover_01 = []\n",
    "    landcover_02 = []\n",
    "    landcover_03 = []\n",
    "    roughness = []\n",
    "    surface_temp = []\n",
    "    vo = []\n",
    "    veg_wat_cont = []\n",
    "\n",
    "    for lat in range(len(sm['latitude'])):\n",
    "        for long in range(len(sm['longitude'][lat])):\n",
    "            latitudes.append(sm['latitude'][lat][long])\n",
    "            longitudes.append(sm['longitude'][lat][long])\n",
    "            moistures.append(sm['soil_moisture'][lat][long])\n",
    "            times.append(sm['tb_time_utc'][lat][long])\n",
    "            qfs.append(sm['retrieval_qual_flag'][lat][long])\n",
    "            # landcover_01.append(sm['landcover_class.Bands_01'][lat][long])\n",
    "            # landcover_02.append(sm['landcover_class.Bands_02'][lat][long])\n",
    "            # landcover_03.append(sm['landcover_class.Bands_03'][lat][long])\n",
    "            roughness.append(sm['roughness_coefficient'][lat][long])\n",
    "            surface_temp.append(sm['surface_temperature'][lat][long])\n",
    "            vo.append(sm['vegetation_opacity'][lat][long])\n",
    "            veg_wat_cont.append(sm['vegetation_water_content'][lat][long])\n",
    "\n",
    "    \"\"\"df = pd.DataFrame.from_dict({'lat': latitudes, 'long': longitudes, 'time': times, 'smap_sm': moistures,\n",
    "                                 'retrieval_qfs': qfs, 'surface_roughness': roughness,\n",
    "                                 'surface_temp': surface_temp, 'vegetation_opacity': vo,\n",
    "                                 'vegetation_water_content': veg_wat_cont, 'landcover_class_01': landcover_01,\n",
    "                                 'landcover_class_02': landcover_02, 'landcover_class_03': landcover_03})\"\"\"\n",
    "    df = pd.DataFrame.from_dict({'lat': latitudes, 'long': longitudes, 'time': times, 'smap_sm': moistures,\n",
    "                                'retrieval_qfs': qfs, 'surface_roughness': roughness,\n",
    "                                'surface_temp': surface_temp, 'vegetation_opacity': vo,\n",
    "                                'vegetation_water_content': veg_wat_cont})\n",
    "\n",
    "    # Filter out missing values\n",
    "    smap_df = df[df['smap_sm'] != -9999.0]\n",
    "\n",
    "    return smap_df\n",
    "\n",
    "\n",
    "def conv(t):\n",
    "    try:\n",
    "        return pd.Timestamp(t)\n",
    "    except:\n",
    "        return pd.Timestamp(t.split('.')[0] + '.000Z')\n",
    "\n",
    "\n",
    "def convert_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ref_date = pd.Timestamp('2020-01-01T00:00:00.000Z')\n",
    "\n",
    "    df['time'] = df['time'].apply(lambda t: conv(t))\n",
    "    df['time'] = df['time'].apply(lambda t: (t - ref_date).days * 24 + (t - ref_date).seconds / 3600)\n",
    "    return df\n",
    "\n",
    "def get_smap_main(root_path: str, year: int, month: int, days: list) -> pd.DataFrame:\n",
    "    first = True\n",
    "    subdirs = []\n",
    "    filenames = []\n",
    "\n",
    "    for dir_name, subdir_list, file_list in os.walk(root_path):\n",
    "        if first:\n",
    "            subdirs = subdir_list\n",
    "            first = False\n",
    "        else:\n",
    "            filenames.append(file_list[0])\n",
    "    \n",
    "    smap_df = pd.DataFrame()\n",
    "    \n",
    "    for i in progressbar(range(len(subdirs))):\n",
    "        current_day = int(filenames[i].split('_')[5][6:8])\n",
    "        current_month = int(filenames[i].split('_')[5][4:6])\n",
    "        current_year = int(filenames[i].split('_')[5][:4])\n",
    "        \n",
    "        if (current_day in days) and (current_year == year) and (current_month == month):\n",
    "            current_path = root_path + '/' + subdirs[i] + '/' + filenames[i]\n",
    "            current_df = get_smap(current_path)\n",
    "            smap_df = smap_df.append(current_df)\n",
    "    \n",
    "    # smap_df = convert_time(smap_df)\n",
    "    \n",
    "    return smap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "\n",
    "def universal_plot(df, target_value='swvl1', title=None, bar_title=None, vmin=None, vmax=None, save=None, dot_size=0.5, std=False, fig_size=None, regions=None, region_colors=None, region_names=None):\n",
    "    \n",
    "    if fig_size is not None:\n",
    "        plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    else:\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "    \n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    lat_list, long_list = get_plot_ticks(df['lat'], df['long'])\n",
    "    ax.set_xticks(long_list, crs=ccrs.PlateCarree())\n",
    "    ax.set_yticks(lat_list, crs=ccrs.PlateCarree())\n",
    "    ax.xaxis.set_major_formatter(LongitudeFormatter())\n",
    "    ax.yaxis.set_major_formatter(LatitudeFormatter())\n",
    "    \n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    \n",
    "    if std:\n",
    "        cmap = 'Greys'\n",
    "    else:\n",
    "        cmap = 'Spectral'\n",
    "        \n",
    "    if vmin is not None:\n",
    "        plt.scatter(df['long'], df['lat'], c=list(df[target_value]), s=dot_size, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        plt.scatter(df['long'], df['lat'], c=list(df[target_value]), s=dot_size, cmap=cmap)\n",
    "    \n",
    "    bar = plt.colorbar(shrink=0.7)\n",
    "    bar.ax.tick_params(labelsize=15)\n",
    "    if bar_title is not None:\n",
    "        bar.ax.set_title(bar_title, fontsize=18)\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=20, fontweight='book')\n",
    "    \n",
    "    if regions is not None:\n",
    "        legend_elements = []\n",
    "        \n",
    "        for i in range(len(regions)):\n",
    "            ax.add_patch(regions[i])\n",
    "            legend_elements.append(Line2D([0], [0], color=region_colors[i], lw=3, label=region_names[i]))\n",
    "\n",
    "        ax.legend(handles=legend_elements, loc='upper right', fontsize=16)\n",
    "        \n",
    "    plt.xlabel('Longitude', fontsize=18)\n",
    "    plt.ylabel('Latitude', fontsize=18)\n",
    "    \n",
    "    if save is not None:\n",
    "        plt.savefig(save, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def get_plot_ticks(lat_values, long_values):\n",
    "    min_lat = min(lat_values)\n",
    "    max_lat = max(lat_values)\n",
    "    min_long = min(long_values)\n",
    "    max_long = max(long_values)\n",
    "    \n",
    "    lat_step_size = (max_lat - min_lat) / 3\n",
    "    long_step_size = (max_long - min_long) / 3\n",
    "    \n",
    "    long_list = [min_long, min_long + long_step_size, min_long + 2 * long_step_size, max_long]\n",
    "    lat_list = [min_lat, min_lat + lat_step_size, min_lat + 2 * lat_step_size, max_lat]\n",
    "    \n",
    "    # Rounding to two decimals\n",
    "    long_list = [round(num, 2) for num in long_list]\n",
    "    lat_list = [round(num, 2) for num in lat_list]\n",
    "    \n",
    "    return lat_list, long_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CYGNSS Variables\n",
    "last_semester_area = {'north': 32.5, 'south': 24.7, 'west': 69.6, 'east': 79.8}\n",
    "\n",
    "selected_area = last_semester_area\n",
    "\n",
    "cygnss_root_path = '/Volumes/Seagate Ekstern Hardisk/CYGNSS Data/CYGNSS 2020-01'\n",
    "year = 2020\n",
    "month = 1\n",
    "start_day = 1\n",
    "end_day = 31\n",
    "days = list(range(start_day, end_day + 1))\n",
    "angle_interval = [0, 60]\n",
    "\n",
    "qf1_removal = True\n",
    "\n",
    "# SMAP Variables\n",
    "smap_root_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Semester Project Area/Jan 2020'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/Seagate Ekstern Hardisk/CYGNSS Data/CYGNSS 2020-01/raw_main_df_2020_01_1of31.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/11/0v6dl9dd455c1b47f6bgcq4c0000gp/T/ipykernel_97682/3641008556.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcygnss_df_raw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_cygnss_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcygnss_root_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdays\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmonth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mselected_area\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mangle_interval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/11/0v6dl9dd455c1b47f6bgcq4c0000gp/T/ipykernel_97682/777195245.py\u001B[0m in \u001B[0;36mget_cygnss_df\u001B[0;34m(root_path, days, month, area, inc_angle_interval)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mday\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdays\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m         \u001B[0mcurrent_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mroot_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mfile_start\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mday\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mfile_ending\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 62\u001B[0;31m         \u001B[0mcurrent_cygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_surface_reflectivity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilter_cygnss_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marea\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     63\u001B[0m         \u001B[0mcurrent_cygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfilter_inc_angle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_cygnss_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minc_angle_interval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0mcurrent_cygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_hours_after_jan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_cygnss_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 811\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1038\u001B[0m             )\n\u001B[1;32m   1039\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1041\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \"\"\"\n\u001B[0;32m--> 222\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    700\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 702\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Volumes/Seagate Ekstern Hardisk/CYGNSS Data/CYGNSS 2020-01/raw_main_df_2020_01_1of31.csv'"
     ]
    }
   ],
   "source": [
    "cygnss_df_raw = get_cygnss_df(cygnss_root_path, days, month, selected_area, angle_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cygnss_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_df = filter_quality_flags_1(cygnss_df_raw)\n",
    "\n",
    "filtering_df = grid_box(filtering_df, 'sr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_size = 2.9\n",
    "\n",
    "area1 = {'north': 32.5, 'south': 29.5, 'west': 69.6, 'east': 72.6}\n",
    "area2 = {'north': 31.0, 'south': 28.0, 'west': 72.5, 'east': 75.5}\n",
    "area3 = {'north': 32.5, 'south': 29.5, 'west': 72.0, 'east': 75.0}\n",
    "area4 = {'north': 27.7, 'south': 24.7, 'west': 76.4, 'east': 79.4}\n",
    "area5 = {'north': 27.9, 'south': 24.9, 'west': 71.0, 'east': 74.0}\n",
    "\n",
    "region_colors = ['red', 'blue', 'purple', 'grey', 'green']  \n",
    "\n",
    "regions = [Rectangle((area1['west'], area1['south']), area1['east'] - area1['west'], area1['north'] - area1['south'], lw=3, fill=False, edgecolor=region_colors[0]),\n",
    "           Rectangle((area2['west'], area2['south']), area2['east'] - area2['west'], area2['north'] - area2['south'], lw=3, fill=False, edgecolor=region_colors[1]),\n",
    "           Rectangle((area3['west'], area3['south']), area3['east'] - area3['west'], area3['north'] - area3['south'], lw=3, fill=False, edgecolor=region_colors[2]),\n",
    "           Rectangle((area4['west'], area4['south']), area4['east'] - area4['west'], area4['north'] - area4['south'], lw=3, fill=False, edgecolor=region_colors[3]),\n",
    "           Rectangle((area5['west'], area5['south']), area5['east'] - area5['west'], area5['north'] - area5['south'], lw=3, fill=False, edgecolor=region_colors[4])]\n",
    "\n",
    "area_names = ['Area 1', 'Area 2', 'Area 3', 'Area 4', 'Area 5']\n",
    "\n",
    "universal_plot(filtering_df, target_value='sr', \n",
    "               title='CYGNSS SR January 2020 Without Smoothening', \n",
    "               bar_title='SR [dB]', \n",
    "               save=None, \n",
    "               dot_size=d_size, \n",
    "               std=False, \n",
    "               fig_size=(10, 10), \n",
    "               regions=regions,\n",
    "               region_colors=region_colors,\n",
    "               region_names=area_names)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtering_df = filter_quality_flags_1(cygnss_df_raw)\n",
    "\n",
    "filtering_df = grid_box(filtering_df, 'sr', True)\n",
    "\n",
    "d_size = 2.9\n",
    "\n",
    "universal_plot(filtering_df, target_value='sr', \n",
    "               title='CYGNSS SR January 2020 Without Smoothening', \n",
    "               bar_title='SR [dB]', \n",
    "               save=None, \n",
    "               dot_size=d_size, \n",
    "               std=False, \n",
    "               fig_size=(10, 10), \n",
    "               regions=None)\n",
    "\n",
    "avg_sr = filtering_df['sr'].mean()\n",
    "filtering_df.loc[len(filtering_df.index)] = [71.5, 24.7, avg_sr] \n",
    "\n",
    "\n",
    "universal_plot(smoothening(filtering_df, selected_area, 0.5, 'sr'), target_value='sr', \n",
    "               title='CYGNSS SR January 2020 Sigma = 0.5', \n",
    "               bar_title='SR [dB]', \n",
    "               save=None, \n",
    "               dot_size=d_size, \n",
    "               std=False, \n",
    "               fig_size=(10, 10), \n",
    "               regions=None)\n",
    "\n",
    "universal_plot(smoothening(filtering_df, selected_area, 1, 'sr'), target_value='sr', \n",
    "               title='CYGNSS SR January 2020 Sigma = 1', \n",
    "               bar_title='SR [dB]', \n",
    "               save=None, \n",
    "               dot_size=d_size, \n",
    "               std=False, \n",
    "               fig_size=(10, 10), \n",
    "               regions=None)\n",
    "\n",
    "universal_plot(smoothening(filtering_df, selected_area, 2, 'sr'), target_value='sr', \n",
    "               title='CYGNSS SR January 2020 Sigma = 2', \n",
    "               bar_title='SR [dB]', \n",
    "               save=None, \n",
    "               dot_size=d_size, \n",
    "               std=False, \n",
    "               fig_size=(10, 10), \n",
    "               regions=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if qf1_removal:\n",
    "    cygnss_df = filter_quality_flags_1(cygnss_df_raw)\n",
    "else:\n",
    "    cygnss_df = cygnss_df_raw\n",
    "\n",
    "# Grid boxing CYGNSS\n",
    "cygnss_df = grid_box(cygnss_df)\n",
    "cygnss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smap_df_raw = get_smap_main(smap_root_path, year, month, days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smap_df = filter_cygnss_df(smap_df_raw, selected_area)\n",
    "smap_df = grid_box(smap_df, 'smap_sm', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_plot(cygnss_df, 'sr',\n",
    "              title='CYGNSS Jan 2020',\n",
    "              bar_title='SR [dB]',\n",
    "              dot_size=8)\n",
    "\n",
    "universal_plot(smap_df, 'smap_sm',\n",
    "              title='SMAP Jan 2020',\n",
    "              bar_title='SM [cm^3/cm^3]',\n",
    "              dot_size=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area1 = {'north': 32.5, 'south': 29.5, 'west': 69.6, 'east': 72.6}\n",
    "area2 = {'north': 31.0, 'south': 28.0, 'west': 72.5, 'east': 75.5}\n",
    "area3 = {'north': 32.5, 'south': 29.5, 'west': 72.0, 'east': 75.0}\n",
    "area4 = {'north': 27.7, 'south': 24.7, 'west': 76.4, 'east': 79.4}\n",
    "area5 = {'north': 27.9, 'south': 24.9, 'west': 71.0, 'east': 74.0}\n",
    "\n",
    "smoothening_areas = [area1, area2, area3, area4, area5]\n",
    "smooth_lists = []\n",
    "for a in smoothening_areas:\n",
    "    current_cyg = filter_cygnss_df(cygnss_df, a)\n",
    "    current_smap = filter_cygnss_df(smap_df, a)\n",
    "    \n",
    "    smooth_list = smoothening_analysis(current_cyg, current_smap, a, 0, 20, use_plot=False)\n",
    "    smooth_lists.append(smooth_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = plt.axes()\n",
    "\n",
    "i = 1\n",
    "for smooth_list in smooth_lists:\n",
    "    ax.plot(smooth_list.keys(), smooth_list.values(), linewidth=3, label='Area ' + str(i))\n",
    "    i = i + 1\n",
    "plt.title('Smoothening Analysis', fontsize=20)\n",
    "plt.xlabel('Sigma', fontsize=14)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=14)\n",
    "plt.legend(fontsize='large', loc='center right')\n",
    "plt.savefig('/Users/vegardhaneberg/Desktop/Plots Master/Smoothening/main_smoothening.png', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_name = 'Area 5'\n",
    "area5 = {'north': 27.9, 'south': 24.9, 'west': 71.0, 'east': 74.0}\n",
    "analysed_area = area5\n",
    "best_sigma = 13.2\n",
    "\n",
    "save_path = '/Users/vegardhaneberg/Desktop/Plots Master/Smoothening/Best Sigma Plots/' + area_name + '/'\n",
    "universal_plot(filter_cygnss_df(cygnss_df, analysed_area), 'sr',\n",
    "              title='CYGNSS ' + area_name + ' without Smoothening',\n",
    "              bar_title='SM [dB]',\n",
    "              dot_size=38,\n",
    "              save= save_path + area_name + ' Without Smoothening')\n",
    "\n",
    "universal_plot(smoothening(filter_cygnss_df(cygnss_df, analysed_area), analysed_area, best_sigma, 'sr'), 'sr',\n",
    "              title='CYGNSS ' + area_name + ' with Sigma = ' + str(best_sigma),\n",
    "              bar_title='SR [db]',\n",
    "              dot_size=38,\n",
    "              save=save_path + area_name + ' With Smoothening')\n",
    "\n",
    "universal_plot(filter_cygnss_df(smap_df, analysed_area), 'smap_sm',\n",
    "              title='SMAP ' + area_name,\n",
    "              bar_title='SM [cm^3/cm^3]',\n",
    "              dot_size=38,\n",
    "              save=save_path + area_name + ' SMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "########## MAIN SMOOTHENING ANALYSIS ##########\n",
    "################################################\n",
    "\n",
    "# Areas\n",
    "africa = {'north': -7, 'south': -12, 'west': 23, 'east': 28}\n",
    "brazil = {'north': -5, 'south': -10, 'west': -42, 'east': -37}\n",
    "australia = {'north': -22, 'south': -27, 'west': 117, 'east': 122}\n",
    "iran = {'north': 31, 'south': 26, 'west': 59, 'east': 64}\n",
    "india = {'north': 24, 'south': 19, 'west': 80, 'east': 85}\n",
    "\n",
    "year = 2020\n",
    "month = 1\n",
    "start_day = 1\n",
    "end_day = 31\n",
    "days = list(range(start_day, end_day + 1))\n",
    "angle_interval = [0, 60]\n",
    "\n",
    "qf1_removal = True\n",
    "\n",
    "# CYGNSS paths\n",
    "cygnss_africa_path = '/Volumes/Seagate Ekstern Hardisk/Processed Files/-7-23--12-28/CYGNSS2020-withQFs-[-7-23--12-28].csv'\n",
    "cygnss_brazil_path = '/Volumes/Seagate Ekstern Hardisk/Processed Files/-5--42--10--37/CYGNSS2020-withQFs-[-5--42--10--37].csv'\n",
    "cygnss_australia_path = '/Volumes/Seagate Ekstern Hardisk/Processed Files/-22-117--27-122/CYGNSS2020-withQFs-[-22-117--27-122].csv'\n",
    "cygnss_iran_path = '/Volumes/Seagate Ekstern Hardisk/Processed Files/31-59-26-64/CYGNSS2020-withQFs-[31-59-26-64].csv'\n",
    "cygnss_india_path = '/Volumes/Seagate Ekstern Hardisk/Processed Files/24-80-19-85/CYGNSS2020-withQFs-[24-80-19-85].csv'\n",
    "\n",
    "# SMAP Paths\n",
    "smap_africa_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Jan 2020 Africa'\n",
    "smap_brazil_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Jan 2020 Brazil'\n",
    "smap_australia_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Jan 2020 Australia'\n",
    "smap_iran_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Jan 2020 Iran'\n",
    "smap_india_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Jan 2020 India'\n",
    "\n",
    "areas = [africa, brazil, australia, iran, india]\n",
    "cygnss_paths = [cygnss_africa_path, cygnss_brazil_path, cygnss_australia_path, cygnss_iran_path, cygnss_india_path]\n",
    "smap_paths = [smap_africa_path, smap_brazil_path, smap_australia_path, smap_iran_path, smap_india_path]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Africa\n",
    "\n",
    "africa_df = pd.read_csv(cygnss_africa_path).rename(columns={'sp_lat': 'lat', 'sp_lon': 'long'})\n",
    "current_cygnss_df = filter_quality_flags_1(africa_df, False)\n",
    "africa_df_grid_boxed = grid_box(africa_df)\n",
    "universal_plot(africa_df_grid_boxed, 'sr', \n",
    "               title='CYGNSS SR Africa Jan 2020', \n",
    "               bar_title='SR [dB]', \n",
    "               save=None, \n",
    "               dot_size=25)\n",
    "\n",
    "africa_smap_df = get_smap_main(smap_africa_path, year, month, days)\n",
    "africa_smap_df_grid_boxed = grid_box(africa_smap_df, 'smap_sm', False)\n",
    "universal_plot(africa_smap_df_grid_boxed, 'smap_sm', \n",
    "               title='SMAP SM Africa Jan 2020', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save=None, \n",
    "               dot_size=15)\n",
    "\n",
    "smoothening_analysis(africa_df_grid_boxed, africa_smap_df_grid_boxed, africa, start_sig=0, end_sig=10, interval=0.1, save=None)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = grid_box(africa_smap_df, 'smap_sm', True)\n",
    "universal_plot(test, 'smap_sm', \n",
    "               title='SMAP SM Africa Jan 2020', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save=None, \n",
    "               dot_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_brazil_df = pd.read_csv(cygnss_brazil_path).rename(columns={'sp_lat': 'lat', 'sp_lon': 'long'})\n",
    "# raw_brazil_smap_df = get_smap_main(smap_brazil_path, year, month, days)\n",
    "raw_brazil_smap_df = brazil_smap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brazil\n",
    "test_brazil = {'north': -5, 'south': -8, 'west': -42, 'east': -39}\n",
    "\n",
    "# brazil_df = pd.read_csv(cygnss_brazil_path).rename(columns={'sp_lat': 'lat', 'sp_lon': 'long'})\n",
    "brazil_df = raw_brazil_df\n",
    "brazil_df = filter_cygnss_df(brazil_df, test_brazil)\n",
    "brazil_df = filter_quality_flags_1(brazil_df, False)\n",
    "brazil_df_grid_boxed = grid_box(brazil_df)\n",
    "universal_plot(brazil_df_grid_boxed, 'sr', \n",
    "               title='CYGNSS SR Brazil Jan 2020', \n",
    "               bar_title='SR [dB]', \n",
    "               save=None, \n",
    "               dot_size=45)\n",
    "\n",
    "# brazil_smap_df = get_smap_main(smap_brazil_path, year, month, days)\n",
    "brazil_smap_df = raw_brazil_smap_df\n",
    "brazil_smap_df = filter_cygnss_df(brazil_smap_df, test_brazil)\n",
    "brazil_smap_df_grid_boxed = grid_box(brazil_smap_df, 'smap_sm', False)\n",
    "universal_plot(brazil_smap_df_grid_boxed, 'smap_sm', \n",
    "               title='SMAP SM Brazil Jan 2020', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save=None, \n",
    "               dot_size=45)\n",
    "\n",
    "smothening_list = smoothening_analysis(brazil_df_grid_boxed, brazil_smap_df_grid_boxed, test_brazil, start_sig=0, end_sig=10, interval=0.1, save=None)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(np.abs(list(smothening_list.values()))))\n",
    "min_index = list(smothening_list.values()).index(min(list(smothening_list.values())))\n",
    "print(list(smothening_list.keys())[min_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_with_smoothening_data = []\n",
    "\n",
    "for i in range(len(areas)):\n",
    "    current_area = areas[i]\n",
    "    current_cygnss_path = cygnss_paths[i]\n",
    "    current_smap_path = smap_paths[i]\n",
    "    \n",
    "    current_cygnss_df = pd.read_csv(current_cygnss_path).rename(columns={'sp_lat': 'lat', 'sp_lon': 'long'})\n",
    "    if qf1_removal:\n",
    "        current_cygnss_df = filter_quality_flags_1(current_cygnss_df, False)\n",
    "    current_cygnss_df = grid_box(current_cygnss_df)\n",
    "        \n",
    "    current_smap_df = get_smap_main(current_smap_path, year, month, days)\n",
    "    \n",
    "    current_smap_df = grid_box(current_smap_df, 'smap_sm', False)\n",
    "    \n",
    "    smoothening_list = smoothening_analysis(current_cygnss_df, current_smap_df, current_area, start_sig=0, end_sig=10, interval=0.1, save=None)\n",
    "    \n",
    "    dicts_with_smoothening_data.append(smoothening_list)\n",
    "    \n",
    "    \n",
    "label_names = ['Africa', 'Brazil', 'Australia', 'Iran', 'India']\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i in range(len(dicts_with_smoothening_data)):\n",
    "    plt.plot(list(dicts_with_smoothening_data[i].keys()), list(dicts_with_smoothening_data[i].values()), label=label_names[i])\n",
    "plt.title('Correlation between CYGNSS and SMAP', fontsize=18)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "plt.xlabel('Sigma', fontsize=12)\n",
    "\n",
    "plt.legend(fontsize='small')\n",
    "plt.savefig('/Users/vegardhaneberg/Desktop/Plots Master/Smoothening/main_smoothening.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CYGNSS Variables\n",
    "last_semester_area = {'north': 32.5, 'south': 24.7, 'west': 69.6, 'east': 79.8}\n",
    "africa = {'north': -7, 'south': -12, 'west': 23, 'east': 28}\n",
    "brazil = {'north': -5, 'south': -10, 'west': -42, 'east': -37}\n",
    "australia = {'north': -22, 'south': -27, 'west': 117, 'east': 122}\n",
    "iran = {'north': 31, 'south': 26, 'west': 59, 'east': 64}\n",
    "india = {'north': 24, 'south': 19, 'west': 80, 'east': 85}\n",
    "\n",
    "selected_area = last_semester_area\n",
    "\n",
    "cygnss_root_path = '/Volumes/Seagate Ekstern Hardisk/CYGNSS Data/CYGNSS 2020-01'\n",
    "year = 2020\n",
    "month = 1\n",
    "start_day = 1\n",
    "end_day = 31\n",
    "days = list(range(start_day, end_day + 1))\n",
    "angle_interval = [0, 60]\n",
    "\n",
    "qf1_removal = True\n",
    "\n",
    "# SMAP Variables\n",
    "smap_root_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Jan 2020 area1'\n",
    "\n",
    "# Start reading CYGNSS\n",
    "cygnss_df = get_cygnss_df(cygnss_root_path, days, month, selected_area, angle_interval)\n",
    "\n",
    "if qf1_removal:\n",
    "    cygnss_df = filter_quality_flags_1(cygnss_df)\n",
    "\n",
    "# Grid boxing CYGNSS\n",
    "cygnss_df = grid_box(cygnss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_coord = (24.7, 71.5)\n",
    "inter_func = interpolate(cygnss_df, 'sr')\n",
    "\n",
    "cygnss_df = cygnss_df.append({'long': float(71.5), 'lat': float(24.7), 'sr': float(inter_func(24.7, 71.5))}, ignore_index=True)\n",
    "cygnss_df['sr'] = pd.to_numeric(cygnss_df['sr'])\n",
    "print(cygnss_df.dtypes)  # All should be float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "def smoothening_with_nan(df: pd.DataFrame, area: dict, sigma: float, target_value='sr') -> pd.DataFrame:\n",
    "    lats = np.arange(area['north'], area['south'] - 0.05, -0.1)\n",
    "    lats = [round(num, 1) for num in lats]\n",
    "    lats_length = len(lats)\n",
    "    longs = np.arange(area['west'], area['east'] + 0.05, 0.1)\n",
    "    longs = [round(num, 1) for num in longs]\n",
    "    longs_length = len(longs)\n",
    "\n",
    "    lats, longs = np.meshgrid(lats, longs, indexing='ij')\n",
    "    lats = lats.flatten()\n",
    "    longs = longs.flatten()\n",
    "    ideal_df = pd.DataFrame.from_dict({'lat': lats, 'long': longs})\n",
    "\n",
    "    df_merged = pd.merge(ideal_df, df, left_on=['lat', 'long'], right_on=['lat', 'long'], how='left')\n",
    "    df_merged = df_merged.sort_values(['lat', 'long'], ascending=(False, True))\n",
    "    \n",
    "    target_values = np.array(df_merged[target_value]).reshape(lats_length, longs_length)\n",
    "    \n",
    "    target_values = convolve(target_values, Gaussian2DKernel(x_stddev=sigma, y_stddev=sigma, x_size=7, y_size=7))\n",
    "    \n",
    "    ideal_df['smooth_sr'] = target_values.flatten()\n",
    "    return ideal_df\n",
    "    \n",
    "    target_values = target_values.flatten()\n",
    "    df[target_value + '_' + str(sigma)] = target_values\n",
    "    \n",
    "    return df\n",
    "\n",
    "smooth_1 = smoothening_with_nan(cygnss_df, selected_area, 1, 'sr')\n",
    "\n",
    "universal_plot(smooth_1, 'smooth_sr', title='CYGNSS SR', bar_title='SR [dB]', save=False, dot_size=4)\n",
    "\n",
    "smooth_1 = filter_cygnss_df(smooth_1, selected_area)\n",
    "\n",
    "universal_plot(smooth_1, 'smooth_sr', title='CYGNSS SR', bar_title='SR [dB]', save=False, dot_size=4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading SMAP  \n",
    "smap_root_path = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Semester Project Area/Jan 2020'\n",
    "smap_df = get_smap_main(smap_root_path, year, month, days)\n",
    "\n",
    "# Grid boxing SMAP\n",
    "smap_df = grid_box(smap_df, 'smap_sm', False)\n",
    "smap_df.head()\n",
    "\n",
    "# Plot grid boxed SMAP and CYGNSS\n",
    "universal_plot(smap_df, 'smap_sm', \n",
    "               title='SMAP SM', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save=None, \n",
    "               dot_size=15)\n",
    "\n",
    "universal_plot(cygnss_df, 'sr', \n",
    "               title='CYGNSS SR', \n",
    "               bar_title='SR [db]', \n",
    "               save=None, \n",
    "               dot_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_same = RectanglePixelRegion(center=PixCoord(x=73.7, y=31), width=3, height=3)\n",
    "region_diff = RectanglePixelRegion(center=PixCoord(x=74.5, y=29), width=3, height=3)\n",
    "\n",
    "universal_plot(cygnss_df, 'sr', \n",
    "               title='CYGNSS SR', \n",
    "               bar_title='SR [db]',\n",
    "               fig_size=(10,10),\n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/Areas variable soil analysis', \n",
    "               dot_size=6,\n",
    "               regions=[region_same, region_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Legge til vmin og vmax i soil moisture plotsa så man lettere ser at det er jevnere i same cyg plot\n",
    "\n",
    "# Lage et plot som viser hvilke områder som er brukt.\n",
    "\n",
    "# Kjøre all kode og lage en tabell med resultatene som kan skrives om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis before the meeting with Mostafa\n",
    "same_soil_type_area = {'north': 32.5, 'south': 29.5, 'west': 72.2, 'east': 75.2}\n",
    "diff_soil_type_area = {'north': 30.5, 'south': 27.5, 'west': 73, 'east': 76}\n",
    "\n",
    "same_cyg_df_jan = filter_cygnss_df(cygnss_df, same_soil_type_area)\n",
    "diff_cyg_df_jan = filter_cygnss_df(cygnss_df, diff_soil_type_area)\n",
    "\n",
    "same_smap_df_jan = filter_cygnss_df(smap_df, same_soil_type_area)\n",
    "diff_smap_df_jan = filter_cygnss_df(smap_df, diff_soil_type_area)\n",
    "\n",
    "vmin_cygnss = min(same_cyg_df_jan['sr'].min(), diff_cyg_df_jan['sr'].min())\n",
    "vmax_cygnss = max(same_cyg_df_jan['sr'].max(), diff_cyg_df_jan['sr'].max())\n",
    "\n",
    "vmin_smap = min(same_smap_df_jan['smap_sm'].min(), diff_smap_df_jan['smap_sm'].min())\n",
    "vmax_smap = max(same_smap_df_jan['smap_sm'].max(), diff_smap_df_jan['smap_sm'].max())\n",
    "\n",
    "universal_plot(same_cyg_df_jan, \n",
    "               'sr', \n",
    "               title='CYGNSS SR Uniform SM Jan 2020', \n",
    "               bar_title='SR [dB]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/same SM cygnss jan',\n",
    "               vmin=vmin_cygnss,\n",
    "               vmax=vmax_cygnss,\n",
    "               dot_size=35)\n",
    "\n",
    "universal_plot(same_smap_df_jan, \n",
    "               'smap_sm', \n",
    "               title='SMAP SM Uniform SM Jan 2020', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/same SM smap jan', \n",
    "               vmin=vmin_smap,\n",
    "               vmax=vmax_smap,\n",
    "               dot_size=35)\n",
    "\n",
    "universal_plot(diff_cyg_df_jan, \n",
    "               'sr', \n",
    "               title='CYGNSS SR Variable SM Jan 2020', \n",
    "               bar_title='SR [dB]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/diff SM cygnss jan',\n",
    "               vmin=vmin_cygnss,\n",
    "               vmax=vmax_cygnss,\n",
    "               dot_size=35)\n",
    "\n",
    "universal_plot(diff_smap_df_jan, \n",
    "               'smap_sm', \n",
    "               title='SMAP SM Variable SM Jan 2020', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/diff SM smap jan',\n",
    "               vmin=vmin_smap,\n",
    "               vmax=vmax_smap,\n",
    "               dot_size=35)\n",
    "\n",
    "merged_same_soil_df_jan = pd.merge(same_cyg_df_jan, same_smap_df_jan, on=['lat', 'long'], how='inner')\n",
    "merged_diff_soil_df_jan = pd.merge(diff_cyg_df_jan, diff_smap_df_jan, on=['lat', 'long'], how='inner')\n",
    "\n",
    "print(merged_same_soil_df_jan['smap_sm'].corr(merged_same_soil_df_jan['sr']))\n",
    "print(merged_diff_soil_df_jan['smap_sm'].corr(merged_diff_soil_df_jan['sr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "#### Same analysis with CYGNSS August #####\n",
    "###########################################\n",
    "\n",
    "year_aug = 2020\n",
    "month_aug = 8\n",
    "start_day = 1\n",
    "end_day = 31\n",
    "days_aug = list(range(start_day, end_day + 1))\n",
    "angle_interval = [0, 60]\n",
    "\n",
    "#Read CYGNSS\n",
    "cygnss_august_2020_root_path = '/Volumes/Seagate Ekstern Hardisk/CYGNSS Data/CYGNSS 2020-08'\n",
    "cygnss_df_aug = get_cygnss_df(cygnss_august_2020_root_path, days_aug, month_aug, selected_area, angle_interval)\n",
    "\n",
    "cygnss_df_aug.head()\n",
    "\n",
    "# Filter bad quality values\n",
    "if qf1_removal:\n",
    "    cygnss_df_aug = filter_quality_flags_1(cygnss_df_aug)\n",
    "\n",
    "# Grid box CYGNSS\n",
    "cygnss_df_aug = grid_box(cygnss_df_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "##### Same analysis with SMAP August ######\n",
    "###########################################\n",
    "\n",
    "# Read SMAP\n",
    "smap_root_path_aug = '/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/9km/Semester Project Area/Aug 2020/'\n",
    "smap_df_aug = get_smap_main(smap_root_path_aug, year_aug, month_aug, days_aug)\n",
    "\n",
    "# Grid box SMAP\n",
    "smap_df_aug = grid_box(smap_df_aug, 'smap_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "same_cyg_df_aug = filter_cygnss_df(cygnss_df_aug, same_soil_type_area)\n",
    "diff_cyg_df_aug = filter_cygnss_df(cygnss_df_aug, diff_soil_type_area)\n",
    "\n",
    "\n",
    "same_smap_df_aug = filter_cygnss_df(smap_df_aug, same_soil_type_area)\n",
    "diff_smap_df_aug = filter_cygnss_df(smap_df_aug, diff_soil_type_area)\n",
    "\n",
    "vmin_cygnss = min(same_cyg_df_aug['sr'].min(), diff_cyg_df_aug['sr'].min())\n",
    "vmax_cygnss = max(same_cyg_df_aug['sr'].max(), diff_cyg_df_aug['sr'].max())\n",
    "\n",
    "vmin_smap = min(same_smap_df_aug['smap_sm'].min(), diff_smap_df_aug['smap_sm'].min())\n",
    "vmax_smap = max(same_smap_df_aug['smap_sm'].max(), diff_smap_df_aug['smap_sm'].max())\n",
    "\n",
    "universal_plot(same_cyg_df_aug, \n",
    "               'sr', \n",
    "               title='CYGNSS SR Uniform SM Aug 2020', \n",
    "               bar_title='SR [dB]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/same SM cygnss aug',\n",
    "               vmin=vmin_cygnss,\n",
    "               vmax=vmax_cygnss,\n",
    "               dot_size=35)\n",
    "\n",
    "universal_plot(same_smap_df_aug, \n",
    "               'smap_sm', \n",
    "               title='SMAP SM Uniform SM Aug 2020', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/same SM smap aug',\n",
    "               vmin=vmin_smap,\n",
    "               vmax=vmax_smap,\n",
    "               dot_size=35)\n",
    "\n",
    "universal_plot(diff_cyg_df_jan, \n",
    "               'sr', \n",
    "               title='CYGNSS SR Variable SM Aug 2020', \n",
    "               bar_title='SR [dB]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/diff SM cygnss aug', \n",
    "               vmin=vmin_cygnss,\n",
    "               vmax=vmax_cygnss,\n",
    "               dot_size=35)\n",
    "\n",
    "universal_plot(diff_smap_df_aug, \n",
    "               'smap_sm', \n",
    "               title='SMAP SM Variable SM Aug 2020', \n",
    "               bar_title='SM [cm^3/cm^3]', \n",
    "               save='/Users/vegardhaneberg/Desktop/Test Plots/diff SM smap aug',\n",
    "               vmin=vmin_smap,\n",
    "               vmax=vmax_smap,\n",
    "               dot_size=35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_same_soil_df_aug = pd.merge(same_cyg_df_aug, same_smap_df_aug, on=['lat', 'long'], how='inner')\n",
    "merged_diff_soil_df_aug = pd.merge(diff_cyg_df_aug, diff_smap_df_aug, on=['lat', 'long'], how='inner')\n",
    "\n",
    "print(merged_same_soil_df_aug['smap_sm'].corr(merged_same_soil_df_aug['sr']))\n",
    "print(merged_diff_soil_df_aug['smap_sm'].corr(merged_diff_soil_df_aug['sr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smoothening_analysis(same_cyg_df_aug, same_smap_df_aug, same_soil_type_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothening_analysis(diff_cyg_df_aug, diff_smap_df_aug, diff_soil_type_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "### Temporal difference analysis ###\n",
    "####################################\n",
    "\n",
    "\n",
    "same_cyg_df_merged = pd.merge(same_cyg_df_aug.rename(columns={'sr': 'sr_aug'}), same_cyg_df_jan.rename(columns={'sr': 'sr_jan'}), on=['lat', 'long'], how='inner')\n",
    "diff_cyg_df_merged = pd.merge(diff_cyg_df_aug.rename(columns={'sr': 'sr_aug'}), diff_cyg_df_jan.rename(columns={'sr': 'sr_jan'}), on=['lat', 'long'], how='inner')\n",
    "\n",
    "same_smap_df_merged = pd.merge(same_smap_df_aug.rename(columns={'smap_sm': 'smap_sm_aug'}), same_smap_df_jan.rename(columns={'smap_sm': 'smap_sm_jan'}), on=['lat', 'long'], how='inner')\n",
    "diff_smap_df_merged = pd.merge(diff_smap_df_aug.rename(columns={'smap_sm': 'smap_sm_aug'}), diff_smap_df_jan.rename(columns={'smap_sm': 'smap_sm_jan'}), on=['lat', 'long'], how='inner')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "same_cyg_df_merged['sr_diff'] = same_cyg_df_merged['sr_jan'] - same_cyg_df_merged['sr_aug']\n",
    "diff_cyg_df_merged['sr_diff'] = diff_cyg_df_merged['sr_jan'] - diff_cyg_df_merged['sr_aug']\n",
    "\n",
    "same_smap_df_merged['smap_sm_diff'] = same_smap_df_merged['smap_sm_jan'] - same_smap_df_merged['smap_sm_aug']\n",
    "diff_smap_df_merged['smap_sm_diff'] = diff_smap_df_merged['smap_sm_jan'] - diff_smap_df_merged['smap_sm_aug']\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "same_temporal_merged = pd.merge(same_cyg_df_merged, same_smap_df_merged, on=['lat', 'long'], how='inner')\n",
    "diff_temporal_merged = pd.merge(diff_cyg_df_merged, diff_smap_df_merged, on=['lat', 'long'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(same_temporal_merged['smap_sm_diff'].corr(same_temporal_merged['sr_diff']))\n",
    "print(diff_temporal_merged['smap_sm_diff'].corr(diff_temporal_merged['sr_diff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothening_analysis(same_cyg_df_merged.rename(columns={'sr_diff': 'sr'}), same_smap_df_merged.rename(columns={'smap_sm_diff': 'smap_sm'}), diff_soil_type_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothening_analysis(diff_cyg_df_merged.rename(columns={'sr_diff': 'sr'}), diff_smap_df_merged.rename(columns={'smap_sm_diff': 'smap_sm'}), diff_soil_type_area)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
